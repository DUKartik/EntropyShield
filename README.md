# EntropyShield: Intelligent Policy Compliance & Enforcement

> **Bridging unstructured policy documents with structured operational data â€” automatically, at scale.**

---

## ğŸ¯ The Problem: The Compliance Gap

In modern enterprises, compliance requirements live in **unstructured documents** (PDFs, contracts, policy memos), while the operational data they govern lives in **structured databases**.

This disconnect forces organisations to rely on slow, error-prone manual audits to enforce rules like:

- *"No dinner expenses over â‚¹2,000."*
- *"Vendor contracts must be renewed every 365 days."*
- *"Employees in Tier-2 cities cannot book Business Class."*

Manual verification cannot scale with modern data velocity.

---

## ğŸ’¡ The Solution: EntropyShield

EntropyShield automates the **full lifecycle of policy enforcement** in four steps:

### 1. Ingest & Interpret â€” Policy Engine
- Upload any unstructured PDF policy document via a drag-and-drop interface.
- **Gemini 1.5 Pro (Vertex AI)** extracts actionable rules from free text.
- Rules are normalised into executable logic (e.g., `IF expense_type == 'Dinner' AND amount > 2000 THEN Flag`).

### 2. Connect & Scan â€” Compliance Monitor
- Connects to the local `company_data.db` (SQLite via SQLAlchemy).
- A background monitor cross-references every record against extracted policy rules.
- **Persistent Rules**: Policies are stored in SQLite so they survive server restarts.
- Delivers **100% transaction coverage, 24/7**.

### 3. Flag, Triage & Explain â€” Live Dashboard
- Violations surface instantly on the **Compliance Dashboard**.
- Each flag includes a plain-language justification derived from the original policy text.
- **Human-in-the-Loop Triage**: Compliance officers can *Approve* or *Reject* violations directly from the dashboard.
- **Audit Trails**: Triaged violations are logged to an `audit_logs` table (including reviewer notes) and excluded from the active KPI count.
- Bento Grid layout with real-time violation feed and interactive charts.

### 4. Verify Integrity â€” VeriDoc Forensic Engine
- Every uploaded policy PDF is scanned **before** ingestion.
- **Structural DNA Analysis:** detects hidden payloads and incremental update tampering.
- **Visual Physics (TruFor + SegFormer):** deep-learning heatmaps reveal pixel-level image splicing in scanned documents.
- **Cryptographic Chain-of-Trust:** validates digital signatures via PyHanko.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Frontend (React 19 + Vite)             â”‚
â”‚  PolicyUploader â†’ DataViewer â†’ ComplianceDashboard             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ REST / JSON
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Backend (FastAPI + Uvicorn)                    â”‚
â”‚                                                                â”‚
â”‚  /api/forensics  â†’  Pipeline Orchestrator                      â”‚
â”‚    â”œâ”€ Pipeline A: Structural Analysis (pypdf, pyhanko)         â”‚
â”‚    â”œâ”€ Pipeline B: Visual Analysis    (SegFormer, ELA, SIFT)    â”‚
â”‚    â””â”€ Pipeline C: Crypto Verification (cryptography, pyhanko)  â”‚
â”‚                                                                â”‚
â”‚  /api/compliance â†’  Policy Engine (Vertex AI / Gemini)         â”‚
â”‚    â”œâ”€ Compliance Monitor (SQLAlchemy â†’ company_data.db)        â”‚
â”‚    â””â”€ Audit Logger (Approvals / False Positive tracking)       â”‚
â”‚                                                                â”‚
â”‚  /api/admin      â†’  Dataset Loader / DB Admin                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Performance Optimisations
- **Zero-Latency Forensic Uploads**: Integrates with GCS `gs://` URIs allowing Vertex AI to read document bytes directly without routing through the backend.
- **Fast Startup via Lazy Loading**: Heavy data science libraries (`torch`, `cv2`, `PIL`, `vertexai`) are rigorously deferred until first use. Server startup takes **~5 seconds** instead of 30+.
- **Query Chunking & Stratification**: Uses chunked SQLAlchemy queries (10k rows) and stratified DB sampling to maintain constant RAM usage regardless of dataset size (e.g., handles the 3GB AML dataset smoothly).

### Technology Stack

| Layer | Technology | Version |
|:---|:---|:---|
| **API Framework** | FastAPI + Uvicorn | 0.129.0 / 0.41.0 |
| **AI / LLM** | Google Vertex AI (Gemini) | `google-cloud-aiplatform` 1.138.0 |
| **Forensic Visual** | PyTorch + Transformers + timm | 2.10.0 / 5.2.0 / 1.0.24 |
| **PDF Processing** | pypdf + pyhanko + pdfminer.six | 6.7.1 / 0.33.0 |
| **Computer Vision** | OpenCV Headless + Pillow | 4.13.0 / 12.1.1 |
| **Database** | SQLAlchemy + SQLite | 2.0.46 |
| **Frontend** | React 19 + Vite + TypeScript | â€” |
| **Styling** | Tailwind CSS v4 | â€” |
| **Python** | CPython | **3.12.10** |
| **Node.js** | Node.js | 20+ |

---

## ğŸš€ Local Setup

### Prerequisites

- **Python 3.12.10** (via [python.org](https://www.python.org/downloads/) or `py -3.12`)
- **Node.js 20+**
- **Google Cloud Project** with Vertex AI API enabled
- A valid `backend/gcp-key.json` service-account key file

---

### Backend

```powershell
# 1. Clone the repository
git clone https://github.com/Start-Impulse/VeriDoc-EntropyShield.git
cd VeriDoc-EntropyShield\backend

# 2. Create and activate a Python 3.12 virtual environment
py -3.12 -m venv venv
.\venv\Scripts\Activate.ps1

# 3. Install all dependencies
pip install -r requirements.txt

# 4. Configure environment variables
copy .env.example .env
# Edit .env with your GCP project ID, credentials path, etc.

# 5. (Optional) Download VeriDoc forensic model weights
python scripts/setup_trufor.py

# 6. Start the API server
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

> **Linux / macOS:** replace `.\venv\Scripts\Activate.ps1` with `source venv/bin/activate`.

The API will be available at `http://localhost:8000`.  
Interactive docs: `http://localhost:8000/docs`

---

### Frontend

```bash
cd ../frontend
npm install
npm run dev
```

The UI will be available at `http://localhost:5173`.

---

## ğŸ“ Project Structure

```
EntropyShield/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                   # FastAPI app entry point
â”‚   â”œâ”€â”€ requirements.txt          # Pinned Python dependencies
â”‚   â”œâ”€â”€ .env.example              # Environment variable template
â”‚   â”œâ”€â”€ company_data.db           # SQLite operational database
â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”œâ”€â”€ forensics.py          # /api/forensics â€” document scanning
â”‚   â”‚   â”œâ”€â”€ compliance.py         # /api/compliance â€” rule checking
â”‚   â”‚   â””â”€â”€ admin.py              # /api/admin â€” DB management
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ policy_engine.py      # Gemini rule extraction
â”‚   â”‚   â”œâ”€â”€ compliance_monitor.py # Background scanning service
â”‚   â”‚   â”œâ”€â”€ database_connector.py # SQLAlchemy connection + seed
â”‚   â”‚   â”œâ”€â”€ dataset_loader.py     # CSV â†’ SQLite ingestion
â”‚   â”‚   â”œâ”€â”€ image_analyzers.py    # ELA, SIFT, metadata analysis
â”‚   â”‚   â””â”€â”€ forensic_reasoning.py # AI forensic report generation
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ pipeline_orchestrator.py
â”‚   â”‚   â”œâ”€â”€ scoring_engine.py
â”‚   â”‚   â”œâ”€â”€ segformer/            # SegFormer forgery detection
â”‚   â”‚   â””â”€â”€ trufor/               # TruFor deep-learning forensics
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ debug_logger.py
â”‚       â””â”€â”€ crypto_utils.py
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ PolicyUploader.tsx
    â”‚   â”‚   â”œâ”€â”€ DataViewer.tsx
    â”‚   â”‚   â””â”€â”€ ComplianceDashboard.tsx
    â”‚   â””â”€â”€ services/
    â””â”€â”€ index.html
```

---

## ğŸ”‘ Environment Variables

Copy `backend/.env.example` to `backend/.env` and fill in:

| Variable | Description |
|:---|:---|
| `GOOGLE_APPLICATION_CREDENTIALS` | Path to your `gcp-key.json` |
| `GCP_PROJECT_ID` | Your Google Cloud project ID |
| `GCP_LOCATION` | Vertex AI region (e.g. `asia-south1`) |
| `TRUFOR_REMOTE_URL` | (Optional) Remote TruFor inference endpoint |

---

**EntropyShield** â€” turn static policy documents into dynamic, automated data guards.
